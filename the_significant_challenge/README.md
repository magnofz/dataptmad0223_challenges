# :see_no_evil: :hear_no_evil: :speak_no_evil: __THE SIGNIFICANT CHALLENGE__ :speak_no_evil: :hear_no_evil: :see_no_evil:

![Image](https://github.com/potacho/the_significant_challenge/blob/master/img/top_banner.jpg)

There are to possible outcomes: if the result comfirms the hypothesis, then you've made a measurement. If the result is contrary to the hypothesis, then you've made a discovery - _Enrico Fermi_

---

## :wrench: __Tools__

You may use any of the following libraries:

- Pandas

- SciPy

- Statsmodels


---

## :hammer: __The Challenge__

You must perform an AB test in order to decide whether the introduction of tailored ads will improve the current Click-Through Rate on your app. The [__notebook__](https://github.com/potacho/the_significant_challenge/blob/master/ab_test_challenge.ipynb) included in this repo will guide you throughout the process. However, you must have a clear understanding of:

- The metrics involved in the test (EDA).

- The experiment design.

- The behaviour before the experiment.

- The behaviour after the experiment.

> __IMPORTANT:__ Hypothesis testing can be a valuable tool when used appropriately, but it is important to remember that it is not infallible. It is subject to error, and the results are influenced by factors such as the sample size, the level of significance chosen, and the assumptions underlying the statistical model. Therefore, it is important to interpret the results of hypothesis testing with caution and to consider the context of the research question and the limitations of the data.

---

## __Would you change the app?__
![Image](https://media.giphy.com/media/9ADoZQgs0tyww/giphy.gif)